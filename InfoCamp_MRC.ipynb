{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InfoCamp-MRC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apeksha104/-DCode---Simplifying-Privacy-Agreements/blob/main/InfoCamp_MRC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1mYA2IPRuC2",
        "outputId": "0bad3362-5760-4438-8ce0-2de19be52a3a"
      },
      "source": [
        "cd /content/drive/MyDrive\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omJntO7_SGvi",
        "outputId": "3f26ebbe-4c2b-408d-a102-e8aa17e37e76"
      },
      "source": [
        "!git clone https://github.com/wasiahmad/PolicyQA.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PolicyQA'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 18 (delta 5), reused 10 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFH4pfHCSIU5",
        "outputId": "57431c08-1413-484d-f264-fd900c4e3774"
      },
      "source": [
        "!pip install tokenizers\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 4.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsz9DYrcSJTZ",
        "outputId": "d2cd7d6c-223a-4a4d-bcc5-90d09cde0fc7"
      },
      "source": [
        "cd PolicyQA/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PolicyQA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4do5SMp5SMSv"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "\n",
        "# ============================================= PREPARING DATASET ======================================================\n",
        "class Sample:\n",
        "    def __init__(self, question, context, start_char_idx=None, answer_text=None, all_answers=None):\n",
        "        self.question = question\n",
        "        self.context = context\n",
        "        self.start_char_idx = start_char_idx\n",
        "        self.answer_text = answer_text\n",
        "        self.all_answers = all_answers\n",
        "        self.skip = False\n",
        "        self.start_token_idx = -1\n",
        "        self.end_token_idx = -1\n",
        "\n",
        "    def preprocess(self):\n",
        "        context = \" \".join(str(self.context).split())\n",
        "        question = \" \".join(str(self.question).split())\n",
        "        tokenized_context = tokenizer.encode(context)\n",
        "        tokenized_question = tokenizer.encode(question)\n",
        "        if self.answer_text is not None:\n",
        "            answer = \" \".join(str(self.answer_text).split())\n",
        "            end_char_idx = self.start_char_idx + len(answer)\n",
        "            if end_char_idx >= len(context):\n",
        "                self.skip = True\n",
        "                return\n",
        "            is_char_in_ans = [0] * len(context)\n",
        "            for idx in range(self.start_char_idx, end_char_idx):\n",
        "                is_char_in_ans[idx] = 1\n",
        "            ans_token_idx = []\n",
        "            for idx, (start, end) in enumerate(tokenized_context.offsets):\n",
        "                if sum(is_char_in_ans[start:end]) > 0:\n",
        "                    ans_token_idx.append(idx)\n",
        "            if len(ans_token_idx) == 0:\n",
        "                self.skip = True\n",
        "                return\n",
        "            self.start_token_idx = ans_token_idx[0]\n",
        "            self.end_token_idx = ans_token_idx[-1]\n",
        "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
        "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(tokenized_question.ids[1:])\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "        padding_length = max_seq_length - len(input_ids)\n",
        "        if padding_length > 0:\n",
        "            input_ids = input_ids + ([0] * padding_length)\n",
        "            attention_mask = attention_mask + ([0] * padding_length)\n",
        "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "        elif padding_length < 0:\n",
        "            self.skip = True\n",
        "            return\n",
        "        self.input_word_ids = input_ids\n",
        "        self.input_type_ids = token_type_ids\n",
        "        self.input_mask = attention_mask\n",
        "        self.context_token_to_char = tokenized_context.offsets\n",
        "\n",
        "\n",
        "def create_squad_examples(raw_data):\n",
        "    squad_examples = []\n",
        "    for item in raw_data[\"data\"]:\n",
        "        for para in item[\"paragraphs\"]:\n",
        "            context = para[\"context\"]\n",
        "            for qa in para[\"qas\"]:\n",
        "                question = qa[\"question\"]\n",
        "                if \"answers\" in qa:\n",
        "                    answer_text = qa[\"answers\"][0][\"text\"]\n",
        "                    all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n",
        "                    start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
        "                    squad_eg = Sample(question, context, start_char_idx, answer_text, all_answers)\n",
        "                else:\n",
        "                    squad_eg = Sample(question, context)\n",
        "                squad_eg.preprocess()\n",
        "                squad_examples.append(squad_eg)\n",
        "    return squad_examples\n",
        "\n",
        "\n",
        "def create_inputs_targets(squad_examples):\n",
        "    dataset_dict = {\n",
        "        \"input_word_ids\": [],\n",
        "        \"input_type_ids\": [],\n",
        "        \"input_mask\": [],\n",
        "        \"start_token_idx\": [],\n",
        "        \"end_token_idx\": [],\n",
        "    }\n",
        "    for item in squad_examples:\n",
        "        if item.skip == False:\n",
        "            for key in dataset_dict:\n",
        "                dataset_dict[key].append(getattr(item, key))\n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\n",
        "    x = [dataset_dict[\"input_word_ids\"],\n",
        "         dataset_dict[\"input_mask\"],\n",
        "         dataset_dict[\"input_type_ids\"]]\n",
        "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
        "    return x, y\n",
        "# =================================================== TRAINING =========================================================\n",
        "\n",
        "\n",
        "class ValidationCallback(keras.callbacks.Callback):\n",
        "\n",
        "    def normalize_text(self, text):\n",
        "        text = text.lower()\n",
        "        text = \"\".join(ch for ch in text if ch not in set(string.punctuation))\n",
        "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "        text = re.sub(regex, \" \", text)\n",
        "        text = \" \".join(text.split())\n",
        "        return text\n",
        "\n",
        "    def __init__(self, x_eval, y_eval):\n",
        "        self.x_eval = x_eval\n",
        "        self.y_eval = y_eval\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
        "        count = 0\n",
        "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
        "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "            squad_eg = eval_examples_no_skip[idx]\n",
        "            offsets = squad_eg.context_token_to_char\n",
        "            start = np.argmax(start)\n",
        "            end = np.argmax(end)\n",
        "            if start >= len(offsets):\n",
        "                continue\n",
        "            pred_char_start = offsets[start][0]\n",
        "            if end < len(offsets):\n",
        "                pred_char_end = offsets[end][1]\n",
        "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
        "            else:\n",
        "                pred_ans = squad_eg.context[pred_char_start:]\n",
        "            normalized_pred_ans = self.normalize_text(pred_ans)\n",
        "            normalized_true_ans = [self.normalize_text(_) for _ in squad_eg.all_answers]\n",
        "            if normalized_pred_ans in normalized_true_ans:\n",
        "                count += 1\n",
        "        acc = count / len(self.y_eval[0])\n",
        "        print(f\"\\nepoch={epoch + 1}, exact match score={acc:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx1F-meoSOhs"
      },
      "source": [
        "train_path = 'data/train.json'\n",
        "eval_path = 'data/dev.json'\n",
        "with open(train_path) as f: raw_train_data = json.load(f)\n",
        "with open(eval_path) as f: raw_eval_data = json.load(f)\n",
        "max_seq_length = 384"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w71-PqC4SRRt",
        "outputId": "fd2f7d43-2576-4a86-911e-389c90b70706"
      },
      "source": [
        "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_word_ids')\n",
        "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_mask')\n",
        "input_type_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_type_ids')\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=True)\n",
        "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy().decode(\"utf-8\")\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertWordPieceTokenizer(vocab=vocab_file, lowercase=True)\n",
        "train_squad_examples = create_squad_examples(raw_train_data)\n",
        "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
        "print(f\"{len(train_squad_examples)} training points created.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17056 training points created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3gUrWIqSS-u",
        "outputId": "0a8a2eb9-34f4-485a-8f15-8c75271d62e0"
      },
      "source": [
        "\n",
        "eval_squad_examples = create_squad_examples(raw_eval_data)\n",
        "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
        "print(f\"{len(eval_squad_examples)} evaluation points created.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3809 evaluation points created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO8T6fyRSTDb",
        "outputId": "ee36464c-3d1c-45b4-c25d-54288fa4b8ce"
      },
      "source": [
        "\n",
        "start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(sequence_output)\n",
        "start_logits = layers.Flatten()(start_logits)\n",
        "end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(sequence_output)\n",
        "end_logits = layers.Flatten()(end_logits)\n",
        "start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
        "end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
        "model = keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=[start_probs, end_probs])\n",
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "optimizer = keras.optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "model.compile(optimizer=optimizer, loss=[loss, loss])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_type_ids (InputLayer)     [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 input_type_ids[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 384, 1)       768         keras_layer[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 384, 1)       768         keras_layer[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 384)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 384)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 384)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 384)          0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,777\n",
            "Trainable params: 109,483,776\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ9OiWalSWtM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOdXljx6SWvY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3ZRcZa3SWze"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJuhFqenSTFQ",
        "outputId": "bf897db2-2e8a-4b6a-b7be-e98b138e9a3f"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=1, batch_size=4, callbacks=[ValidationCallback(x_eval, y_eval)])\n",
        "model.save_weights(\"./weights.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3732/3732 [==============================] - 2787s 747ms/step - loss: 6.1645 - activation_loss: 3.0852 - activation_1_loss: 3.0793\n",
            "\n",
            "epoch=1, exact match score=0.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS87GwX-SXh5"
      },
      "source": [
        "# test_path='data/test.json'\n",
        "# with open(test_path) as f: raw_test_data = json.load(f)\n",
        "raw_test_data={\"data\": [{\"title\": \"\", \n",
        "          \"paragraphs\": \n",
        "          [{ \"context\": \"The Adobe Privacy Policy describes the privacy practices of Adobe apps and websites. If you are a resident of North America, your relationship is with Adobe Inc and the laws of California and the United States apply. If you reside outside of North America, your relationship is with Adobe Systems Software Ireland Limited, which is the controller with regard to your personal information collected by Adobe and the laws of Ireland apply. Please note that in order to use our apps and websites, you authorise Adobe to transfer your personal information across national borders and to other countries where Adobe and its partners operate, including the United States. The privacy protections and rights of authorities to access your information in these countries may not be equivalent to those in your country. We will only transfer your personal information to these countries where permitted to do so by law and we will take steps intended to ensure that your personal information continues to receive appropriate protections. If the content or information that you store on Adobe apps or websites contains personal information of other individuals, you must be legally permitted to share the personal information with Adobe. We will obtain your permission before sending you news and promotional material about Adobe, accessing information stored on your device relating to your use and engagement with, websites and apps and crash reports, and analysing your content. You can withdraw your consent to such activities at any time. This policy explains when we process personal information for our legitimate interests. You can ask us to stop processing this information. We use your personal information to enable you to register with Adobe and to provide you with our websites and apps and other products or services that you request. We provide interactive features that engage with social media sites, such as Facebook. If you use these features, these sites will send us personal information about you. We use cookies and other technologies to track the use of our websites and apps.. \", \n",
        "              \"qas\": \n",
        "            [{\"question\": \"What does this policy describe?\", \n",
        "              \"id\": \"43d0tj7wcdmhwadk\"},                          \n",
        "             {\"question\": \"What if I am a resident outside of America?\", \n",
        "              \"id\": \"knyp7n1i9r35ci82\"},           \n",
        "             {\"question\": \"Will they expose the data collected from me in social networking sites?\", \n",
        "              \"id\": \"6isrs6pl65f7ueuf\"},              \n",
        "              {\"question\": \"Are my websites and apps tracked by cookies?\", \n",
        "               \"id\": \"xslxbpslfpt535le\"}, \n",
        "             {\"question\": \"Do you follow confidentiality obligations?\", \n",
        "              \"id\": \"qnabo06neuot52m1\"\n",
        "             }\n",
        "            ]}]}]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgUk_4eISXkC",
        "outputId": "02cafd8b-6e0e-46b3-f1d5-7eec48073fcb"
      },
      "source": [
        "test_samples = create_squad_examples(raw_test_data)\n",
        "x_test, _ = create_inputs_targets(test_samples)\n",
        "pred_start, pred_end = model.predict(x_test)\n",
        "for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "    test_sample = test_samples[idx]\n",
        "    offsets = test_sample.context_token_to_char\n",
        "    start = np.argmax(start)\n",
        "    end = np.argmax(end)\n",
        "    pred_ans = None\n",
        "    if start >= len(offsets):\n",
        "        continue\n",
        "    pred_char_start = offsets[start][0]\n",
        "    if end < len(offsets):\n",
        "        pred_ans = test_sample.context[pred_char_start:offsets[end][1]]\n",
        "    else:\n",
        "        pred_ans = test_sample.context[pred_char_start:]\n",
        "    print(\"Q: \" + test_sample.question)\n",
        "    print(\"A: \" + pred_ans)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What does this policy describe?\n",
            "A: The Adobe Privacy Policy describes the privacy practices of Adobe apps and websites. If you are a resident of North America, your relationship is with Adobe Inc and the laws of California and the United States apply. If you reside outside of North America, your relationship is with Adobe Systems Software Ireland Limited, which is the controller with regard to your personal information collected by Adobe and the laws of Ireland apply. Please note that in order to use our apps and websites, you authorise Adobe to transfer\n",
            "Q: What if I am a resident outside of America?\n",
            "A: If you are a resident of North America, your relationship is with Adobe Inc and the laws of California and the United States apply. If you reside outside of North America, your relationship is with Adobe Systems Software Ireland Limited, which is the controller with regard to your personal information collected by Adobe and the laws of Ireland apply. Please note that in order to use our apps and websites, you authorise Adobe to transfer your personal information across national borders\n",
            "Q: Will they expose the data collected from me in social networking sites?\n",
            "A: We will obtain your permission before sending you news and promotional material about Adobe, accessing information stored on your device relating to your use and engagement with, websites and apps and crash reports, and analysing your content. You can withdraw your consent to such activities at any time. This policy explains when we process personal information for our legitimate interests. You can ask us to stop processing this information. We use your personal information to enable you to register with Adobe and to provide you with our websites and apps and other products or services that you request. We provide interactive features that engage with social media sites\n",
            "Q: Are my websites and apps tracked by cookies?\n",
            "A: cookies and other technologies\n",
            "Q: Do you follow confidentiality obligations?\n",
            "A: you authorise Adobe to transfer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9F3qIjjhsqi"
      },
      "source": [
        "raw_test_data={\"data\": [{\"title\": \"\", \n",
        "          \"paragraphs\": \n",
        "          [{ \"context\": \"Please take a moment to review some changes to our Terms and Data Policy . Your Instagram experience isnt changing, and you still own your photos and videos. We are giving you better ways to access your data and understand how its used. By continuing to use Instagram on or after July 14, 2018, you're agreeing to these updates. Instagram has been a part of Facebook since 2012, and we're making some corporate changes. Going forward, our Terms will reflect that Facebook Inc. is responsible for Instagram. The Instagram app and the way we process data are not changing. Our Terms are now more clear about the service we provide, and what we expect from every member of our community to keep Instagram a safe place for everyone. Here are some updates we want to make sure you know about: We updated our intellectual property licenses, but your rights aren't changing. You still own your photos and videos. We updated how we use information to show activity on Instagram, so people can see when you've interacted with an ad the same way we do on a regular post. We also have a new Data Policy that explains how data is collected, shared and used in the Facebook Products, including Instagram. The policy addresses newer features like stories, direct messaging, activity status and the creative tools in our cameras. We wanted to make sure you knew about this new information in the policy. We receive different kinds of information from your device, like how you tap and scroll, which can help distinguish humans from bots and detect fraud. We can use and share information for research, especially in ways that help us keep our community safe on Instagram, like to understand and prevent bullying and harassment. The policy has more information about what we collect from your activity and our partners, how we connect information across the Facebook Companies and how we personalize your experience, including ads. We provide ads without telling advertisers who you are. The policy has more information about what we do share with advertisers and partners. We never sell your data. Because the policy also covers Facebook, it includes information about facial recognition. We dont use facial recognition technology on Instagram. If we introduce it, we will let you know and give you a choice.\", \n",
        "              \"qas\": \n",
        "            [{\"question\": \"What would my cookies be used for?\", \n",
        "              \"id\": \"43d0tj7wcdmhwadk\"},              \n",
        "             {\"question\": \"Why would Instagram store my information?\",  \n",
        "              \"id\": \"hjwapte7oki8t3l5\"},              \n",
        "             {\"question\": \"Why would Instagram keep records about my browsing activity?\", \n",
        "              \"id\": \"knyp7n1i9r35ci82\"},           \n",
        "             {\"question\": \"Why would Instagram share my information with external organisations?\", \n",
        "              \"id\": \"6isrs6pl65f7ueuf\"},              \n",
        "              {\"question\": \"Why does Instagram collect my user name, language or my region?\", \n",
        "               \"id\": \"xslxbpslfpt535le\"}, \n",
        "             {\"question\": \"What kind of advertising would I receive by Instagram or its advertising partners?\", \n",
        "              \"id\": \"qnabo06neuot52m1\"\n",
        "             }\n",
        "            ]}]}]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4RqrRvdSXp1"
      },
      "source": [
        "We use government approved contractual clauses such as European Commission approved Standard Contractual Clauses to help protect your personal information. This privacy policy describes how Adobe will make use of your information in the context of Adobe websites, webbased services such as Behance, and webbased aspects of the Creative Cloud, Document Cloud and Experience Cloud, Desktop apps and mobile apps that include a reference to this policy, and Adobes marketing, sales and advertising practices.  Please note that websites and apps provided by some companies acquired by Adobe may operate under their own privacy policies until their privacy practices are integrated with Adobes privacy practices. When you register to use an Adobe app or website, create an Adobe ID or contact us for support or other offerings, Adobe collects information that identifies you. To help keep our databases current and to provide you the most relevant content and experiences, we may combine information provided by you with information from third party sources, in accordance with applicable law. For example, the size, industry and other information about the company you work for will be obtained from sources including, professional networking sites and information service providers. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l1OaJOQSXrN"
      },
      "source": [
        "If you are a resident of North America, your relationship is with Adobe Inc and the laws of California and the United States apply. If you reside outside of North America, your relationship is with Adobe Systems Software Ireland Limited, which is the controller with regard to your personal information collected by Adobe and the laws of Ireland apply. Please note that in order to use our apps and websites, you authorise Adobe to transfer your personal information across national borders and to other countries where Adobe and its partners operate, including the United States. The privacy protections and rights of authorities to access your information in these countries may not be equivalent to those in your country. We will only transfer your personal information to these countries where permitted to do so by law and we will take steps intended to ensure that your personal information continues to receive appropriate protections. There are several places within Adobes websites and apps that allow you to post comments, upload pictures or submit content which will be publicly available where you choose to participate in these activities. We also disclose personal information to other companies in the Adobe family and with advertising and sales partners consistent with your choices. We also share information with third parties we engage to process personal information on our behalf or when such sharing is required by law or in certain other situations.  We transfer your personal information to the US and other countries, which may be outside the country in which you live. We use government approved contractual clauses such as European Commission approved Standard Contractual Clauses to help protect your personal information. This privacy policy describes how Adobe will make use of your information in the context of Adobe websites, webbased services such as Behance, and webbased aspects of the Creative Cloud, Document Cloud and Experience Cloud, Desktop apps and mobile apps that include a reference to this policy, and Adobes marketing, sales and advertising practices."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DK264bZSXsU"
      },
      "source": [
        "\"data\": [{\"title\": \"neworleansonline.com\", \"paragraphs\": [{\"qas\": [{\"question\": \"Do you take the user's opinion before or after making changes in policy?\", \"type\": \"Policy Change|||User Choice|||None\", \"id\": \"3f23wv3kh9cmvjio\", \"answers\": [{\"text\": \"Last Updated on May 22, 2015\", \"answer_start\": 0}]}, {\"question\": \"How do you inform all the users upon policy changes?\", \"type\": \"Policy Change|||Notification Type|||General notice in privacy policy\", \"id\": \"5mk7ry5up95qrw7v\", \"answers\": [{\"text\": \"Last Updated on May 22, 2015\", \"answer_start\": 0}]}], \"index\": 1, \"context\": \"Last Updated on May 22, 2015\", \"summary\": [\"The text does not fit into our label scheme.\", \"The text introduces the policy, a section, or a group of practices, but it does not mention a specific practice.\", \"When a change of an unspecified nature is made to the privacy policy, the policy date is updated or information about the change is posted as part of the policy. Users have no options regarding the change.\"]}, {\"qas\": [{\"question\": \"What types of choice options available to the users?\", \"type\": \"User Choice/Control|||Choice Type|||Dont use service/feature\", \"id\": \"43d0tj7wcdmhwadk\", \"answers\": [{\"text\": \"If you disagree with any part of this Privacy Policy, please do not use any of our Online Services.\", \"answer_start\": 513}, {\"text\": \"By using or downloading any of our Online Services, you are agreeing that you have read and agree to be bound by this Privacy Policy. If you disagree with any part of this Privacy Policy, please do not use any of our Online Services.\", \"answer_start\": 379}, {\"text\": \"do not use any of our Online Services.\", \"answer_start\": 574}]}, {\"question\": \"What are the users' choices for the data used in providing basic services?\", \"type\": \"User Choice/Control|||Purpose|||Basic service/feature\", \"id\": \"hjwapte7oki8t3l5\", \"answers\": [{\"text\": \"The Privacy Policy applies to your access and use of the NOTMC Websites (as defined in our Terms of Use), mobile applications and other online programs (\\\"Online Services\\\").\", \"answer_start\": 206}]}, {\"question\": \"Does the company collect user's information directly on their website?\", \"type\": \"First Party Collection/Use|||Action First-Party|||Collect on website\", \"id\": \"knyp7n1i9r35ci82\", \"answers\": [{\"text\": \"access and use of the NOTMC Websites (as defined in our Terms of Use)\", \"answer_start\": 241}]}, {\"question\": \"Will they use the data collected from me?\", \"type\": \"First Party Collection/Use|||Does/Does Not|||Does\", \"id\": \"6isrs6pl65f7ueuf\", \"answers\": [{\"text\": \"our personal information collection practices\", \"answer_start\": 122}]}, {\"question\": \"Does the company collects user's information on their mobile app?\", \"type\": \"First Party Collection/Use|||Action First-Party|||Collect in mobile app\", \"id\": \"xslxbpslfpt535le\", \"answers\": [{\"text\": \"mobile applications\", \"answer_start\": 312}]}, {\"question\": \"Do you receive information from other sources?\", \"type\": \"First Party Collection/Use|||Action First-Party|||Receive from other service/third-party (unnamed)\", \"id\": \"qnabo06neuot52m1\", \"answers\": [{\"text\": \"other online programs (\\\"Online Services\\\")\", \"answer_start\": 336}]}]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}